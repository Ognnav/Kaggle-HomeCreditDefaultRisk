{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, seaborn as sns, time, datetime, os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['application_test.csv',\n",
       " 'application_train.csv',\n",
       " 'bureau.csv',\n",
       " 'bureau_balance.csv',\n",
       " 'credit_card_balance.csv',\n",
       " 'HomeCredit_columns_description.csv',\n",
       " 'installments_payments.csv',\n",
       " 'POS_CASH_balance.csv',\n",
       " 'previous_application.csv',\n",
       " 'sample_submission.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### List file path\n",
    "fpath = './home-credit-default-risk/'\n",
    "os.listdir(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 122) (48744, 121)\n"
     ]
    }
   ],
   "source": [
    "### Read training data\n",
    "DF_train = pd.read_csv(fpath+'application_train.csv')\n",
    "### Read testing data\n",
    "DF_test = pd.read_csv(fpath+'application_test.csv')\n",
    "print(DF_train.shape,DF_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "\n",
       "   ...  FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                 0                0                0                0   \n",
       "1  ...                 0                0                0                0   \n",
       "2  ...                 0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        0.0                       0.0   \n",
       "2                        0.0                       0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         1.0  \n",
       "1                        0.0                         0.0  \n",
       "2                        0.0                         0.0  \n",
       "\n",
       "[3 rows x 122 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>568800.0</td>\n",
       "      <td>20560.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>222768.0</td>\n",
       "      <td>17370.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>663264.0</td>\n",
       "      <td>69777.0</td>\n",
       "      <td>630000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  \\\n",
       "0      100001         Cash loans           F            N               Y   \n",
       "1      100005         Cash loans           M            N               Y   \n",
       "2      100013         Cash loans           M            Y               Y   \n",
       "\n",
       "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0             0          135000.0    568800.0      20560.5         450000.0   \n",
       "1             0           99000.0    222768.0      17370.0         180000.0   \n",
       "2             0          202500.0    663264.0      69777.0         630000.0   \n",
       "\n",
       "   ... FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                0                0                0                0   \n",
       "1  ...                0                0                0                0   \n",
       "2  ...                0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR  AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         0.0  \n",
       "1                        0.0                         3.0  \n",
       "2                        1.0                         4.0  \n",
       "\n",
       "[3 rows x 121 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    65\n",
       "int64      41\n",
       "object     16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Find out how many non numeric columns in training data\n",
    "DF_train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY',\n",
       "       'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
       "       'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE',\n",
       "       'WEEKDAY_APPR_PROCESS_START', 'ORGANIZATION_TYPE', 'FONDKAPREMONT_MODE',\n",
       "       'HOUSETYPE_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Find which columns are non numeric\n",
    "DF_train.columns[DF_train.dtypes=='object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    65\n",
       "int64      40\n",
       "object     16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Find out how many non numeric columns in testing data\n",
    "DF_test.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY',\n",
       "       'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
       "       'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE',\n",
       "       'WEEKDAY_APPR_PROCESS_START', 'ORGANIZATION_TYPE', 'FONDKAPREMONT_MODE',\n",
       "       'HOUSETYPE_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Find which columns are non numeric\n",
    "DF_test.columns[DF_test.dtypes=='object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    282686\n",
       "1     24825\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Find how many loans have not been paid on time (TARGET=1)\n",
    "DF_train['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1edfc0d40f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DF_train['TARGET'].astype(int).plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_TYPE_SUITE', 'OWN_CAR_AGE',\n",
       "       'OCCUPATION_TYPE', 'CNT_FAM_MEMBERS', 'EXT_SOURCE_1', 'EXT_SOURCE_2',\n",
       "       'EXT_SOURCE_3', 'APARTMENTS_AVG', 'BASEMENTAREA_AVG',\n",
       "       'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG',\n",
       "       'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'FLOORSMIN_AVG',\n",
       "       'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG',\n",
       "       'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MODE',\n",
       "       'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE',\n",
       "       'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE',\n",
       "       'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE',\n",
       "       'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE',\n",
       "       'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI',\n",
       "       'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI',\n",
       "       'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI',\n",
       "       'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI',\n",
       "       'NONLIVINGAREA_MEDI', 'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE',\n",
       "       'TOTALAREA_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE',\n",
       "       'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE',\n",
       "       'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE',\n",
       "       'DAYS_LAST_PHONE_CHANGE', 'AMT_REQ_CREDIT_BUREAU_HOUR',\n",
       "       'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK',\n",
       "       'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT',\n",
       "       'AMT_REQ_CREDIT_BUREAU_YEAR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Find columns with missing values in training data\n",
    "DF_train.columns[DF_train.isnull().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 246) (48744, 242)\n"
     ]
    }
   ],
   "source": [
    "### Convert categorical columns to numerical columns using one-hot encoding\n",
    "DF_train = pd.get_dummies(DF_train)\n",
    "DF_test = pd.get_dummies(DF_test)\n",
    "print(DF_train.shape,DF_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SK_ID_CURR : Min =  100002 , Max =  456255\n",
      "TARGET : Min =  0 , Max =  1\n",
      "CNT_CHILDREN : Min =  0 , Max =  19\n",
      "AMT_INCOME_TOTAL : Min =  25650.0 , Max =  117000000.0\n",
      "AMT_CREDIT : Min =  45000.0 , Max =  4050000.0\n",
      "AMT_ANNUITY : Min =  1615.5 , Max =  258025.5\n",
      "AMT_GOODS_PRICE : Min =  40500.0 , Max =  4050000.0\n",
      "REGION_POPULATION_RELATIVE : Min =  0.00029 , Max =  0.072508\n",
      "DAYS_BIRTH : Min =  -25229 , Max =  -7489\n",
      "DAYS_EMPLOYED : Min =  -17912 , Max =  365243\n",
      "DAYS_REGISTRATION : Min =  -24672.0 , Max =  0.0\n",
      "DAYS_ID_PUBLISH : Min =  -7197 , Max =  0\n",
      "OWN_CAR_AGE : Min =  nan , Max =  nan\n",
      "FLAG_MOBIL : Min =  0 , Max =  1\n",
      "FLAG_EMP_PHONE : Min =  0 , Max =  1\n",
      "FLAG_WORK_PHONE : Min =  0 , Max =  1\n",
      "FLAG_CONT_MOBILE : Min =  0 , Max =  1\n",
      "FLAG_PHONE : Min =  0 , Max =  1\n",
      "FLAG_EMAIL : Min =  0 , Max =  1\n",
      "CNT_FAM_MEMBERS : Min =  1.0 , Max =  20.0\n",
      "REGION_RATING_CLIENT : Min =  1 , Max =  3\n",
      "REGION_RATING_CLIENT_W_CITY : Min =  1 , Max =  3\n",
      "HOUR_APPR_PROCESS_START : Min =  0 , Max =  23\n",
      "REG_REGION_NOT_LIVE_REGION : Min =  0 , Max =  1\n",
      "REG_REGION_NOT_WORK_REGION : Min =  0 , Max =  1\n",
      "LIVE_REGION_NOT_WORK_REGION : Min =  0 , Max =  1\n",
      "REG_CITY_NOT_LIVE_CITY : Min =  0 , Max =  1\n",
      "REG_CITY_NOT_WORK_CITY : Min =  0 , Max =  1\n",
      "LIVE_CITY_NOT_WORK_CITY : Min =  0 , Max =  1\n",
      "EXT_SOURCE_1 : Min =  0.014568132412445587 , Max =  0.962692770561306\n",
      "EXT_SOURCE_2 : Min =  8.173616518884397e-08 , Max =  0.8549996664047012\n",
      "EXT_SOURCE_3 : Min =  0.0005272652387098817 , Max =  0.8960095494948396\n",
      "APARTMENTS_AVG : Min =  0.0 , Max =  1.0\n",
      "BASEMENTAREA_AVG : Min =  0.0 , Max =  1.0\n",
      "YEARS_BEGINEXPLUATATION_AVG : Min =  0.0 , Max =  1.0\n",
      "YEARS_BUILD_AVG : Min =  0.0 , Max =  1.0\n",
      "COMMONAREA_AVG : Min =  0.0 , Max =  1.0\n",
      "ELEVATORS_AVG : Min =  0.0 , Max =  1.0\n",
      "ENTRANCES_AVG : Min =  0.0 , Max =  1.0\n",
      "FLOORSMAX_AVG : Min =  0.0 , Max =  1.0\n",
      "FLOORSMIN_AVG : Min =  0.0 , Max =  1.0\n",
      "LANDAREA_AVG : Min =  0.0 , Max =  1.0\n",
      "LIVINGAPARTMENTS_AVG : Min =  0.0 , Max =  1.0\n",
      "LIVINGAREA_AVG : Min =  0.0 , Max =  1.0\n",
      "NONLIVINGAPARTMENTS_AVG : Min =  0.0 , Max =  1.0\n",
      "NONLIVINGAREA_AVG : Min =  0.0 , Max =  1.0\n",
      "APARTMENTS_MODE : Min =  0.0 , Max =  1.0\n",
      "BASEMENTAREA_MODE : Min =  0.0 , Max =  1.0\n",
      "YEARS_BEGINEXPLUATATION_MODE : Min =  0.0 , Max =  1.0\n",
      "YEARS_BUILD_MODE : Min =  0.0 , Max =  1.0\n",
      "COMMONAREA_MODE : Min =  0.0 , Max =  1.0\n",
      "ELEVATORS_MODE : Min =  0.0 , Max =  1.0\n",
      "ENTRANCES_MODE : Min =  0.0 , Max =  1.0\n",
      "FLOORSMAX_MODE : Min =  0.0 , Max =  1.0\n",
      "FLOORSMIN_MODE : Min =  0.0 , Max =  1.0\n",
      "LANDAREA_MODE : Min =  0.0 , Max =  1.0\n",
      "LIVINGAPARTMENTS_MODE : Min =  0.0 , Max =  1.0\n",
      "LIVINGAREA_MODE : Min =  0.0 , Max =  1.0\n",
      "NONLIVINGAPARTMENTS_MODE : Min =  0.0 , Max =  1.0\n",
      "NONLIVINGAREA_MODE : Min =  0.0 , Max =  1.0\n",
      "APARTMENTS_MEDI : Min =  0.0 , Max =  1.0\n",
      "BASEMENTAREA_MEDI : Min =  0.0 , Max =  1.0\n",
      "YEARS_BEGINEXPLUATATION_MEDI : Min =  0.0 , Max =  1.0\n",
      "YEARS_BUILD_MEDI : Min =  0.0 , Max =  1.0\n",
      "COMMONAREA_MEDI : Min =  0.0 , Max =  1.0\n",
      "ELEVATORS_MEDI : Min =  0.0 , Max =  1.0\n",
      "ENTRANCES_MEDI : Min =  0.0 , Max =  1.0\n",
      "FLOORSMAX_MEDI : Min =  0.0 , Max =  1.0\n",
      "FLOORSMIN_MEDI : Min =  0.0 , Max =  1.0\n",
      "LANDAREA_MEDI : Min =  0.0 , Max =  1.0\n",
      "LIVINGAPARTMENTS_MEDI : Min =  0.0 , Max =  1.0\n",
      "LIVINGAREA_MEDI : Min =  0.0 , Max =  1.0\n",
      "NONLIVINGAPARTMENTS_MEDI : Min =  0.0 , Max =  1.0\n",
      "NONLIVINGAREA_MEDI : Min =  0.0 , Max =  1.0\n",
      "TOTALAREA_MODE : Min =  0.0 , Max =  1.0\n",
      "OBS_30_CNT_SOCIAL_CIRCLE : Min =  0.0 , Max =  348.0\n",
      "DEF_30_CNT_SOCIAL_CIRCLE : Min =  0.0 , Max =  34.0\n",
      "OBS_60_CNT_SOCIAL_CIRCLE : Min =  0.0 , Max =  344.0\n",
      "DEF_60_CNT_SOCIAL_CIRCLE : Min =  0.0 , Max =  24.0\n",
      "DAYS_LAST_PHONE_CHANGE : Min =  -4292.0 , Max =  0.0\n",
      "FLAG_DOCUMENT_2 : Min =  0 , Max =  1\n",
      "FLAG_DOCUMENT_3 : Min =  0 , Max =  1\n",
      "FLAG_DOCUMENT_4 : Min =  0 , Max =  1\n",
      "FLAG_DOCUMENT_5 : Min =  0 , Max =  1\n",
      "FLAG_DOCUMENT_6 : Min =  0 , Max =  1\n",
      "FLAG_DOCUMENT_7 : Min =  0 , Max =  1\n",
      "FLAG_DOCUMENT_8 : Min =  0 , Max =  1\n",
      "FLAG_DOCUMENT_9 : Min =  0 , Max =  1\n",
      "FLAG_DOCUMENT_10 : Min =  0 , Max =  1\n",
      "FLAG_DOCUMENT_11 : Min =  0 , Max =  1\n",
      "FLAG_DOCUMENT_12 : Min =  0 , Max =  1\n",
      "FLAG_DOCUMENT_13 : Min =  0 , Max =  1\n",
      "FLAG_DOCUMENT_14 : Min =  0 , Max =  1\n",
      "FLAG_DOCUMENT_15 : Min =  0 , Max =  1\n",
      "FLAG_DOCUMENT_16 : Min =  0 , Max =  1\n",
      "FLAG_DOCUMENT_17 : Min =  0 , Max =  1\n",
      "FLAG_DOCUMENT_18 : Min =  0 , Max =  1\n",
      "FLAG_DOCUMENT_19 : Min =  0 , Max =  1\n",
      "FLAG_DOCUMENT_20 : Min =  0 , Max =  1\n",
      "FLAG_DOCUMENT_21 : Min =  0 , Max =  1\n",
      "AMT_REQ_CREDIT_BUREAU_HOUR : Min =  0.0 , Max =  4.0\n",
      "AMT_REQ_CREDIT_BUREAU_DAY : Min =  0.0 , Max =  9.0\n",
      "AMT_REQ_CREDIT_BUREAU_WEEK : Min =  0.0 , Max =  8.0\n",
      "AMT_REQ_CREDIT_BUREAU_MON : Min =  0.0 , Max =  27.0\n",
      "AMT_REQ_CREDIT_BUREAU_QRT : Min =  0.0 , Max =  261.0\n",
      "AMT_REQ_CREDIT_BUREAU_YEAR : Min =  0.0 , Max =  25.0\n"
     ]
    }
   ],
   "source": [
    "### Find anomalies in the original numerical columns\n",
    "for col in DF_train.columns[:106]:\n",
    "    print(col,': Min = ',min(DF_train[col]),', Max = ',max(DF_train[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replace the anomalous value in DAYS_EMPLOYED column (=365243) with np.nan and indicate this in a new column\n",
    "DF_train['DAYS_EMPLOYED_ANOM'] = (DF_train['DAYS_EMPLOYED']==365243).astype(int)\n",
    "DF_train['DAYS_EMPLOYED'].replace({365243:np.nan},inplace=True)\n",
    "DF_test['DAYS_EMPLOYED_ANOM'] = (DF_test['DAYS_EMPLOYED']==365243).astype(int)\n",
    "DF_test['DAYS_EMPLOYED'].replace({365243:np.nan},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Find correlation with the TARGET column\n",
    "corr_train = DF_train.corr()['TARGET'].sort_values()\n",
    "len(corr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EXT_SOURCE_3                           -0.178919\n",
       "EXT_SOURCE_2                           -0.160472\n",
       "EXT_SOURCE_1                           -0.155317\n",
       "NAME_EDUCATION_TYPE_Higher education   -0.056593\n",
       "CODE_GENDER_F                          -0.054704\n",
       "NAME_INCOME_TYPE_Pensioner             -0.046209\n",
       "DAYS_EMPLOYED_ANOM                     -0.045987\n",
       "ORGANIZATION_TYPE_XNA                  -0.045987\n",
       "FLOORSMAX_AVG                          -0.044003\n",
       "FLOORSMAX_MEDI                         -0.043768\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REG_CITY_NOT_WORK_CITY         0.050994\n",
       "DAYS_ID_PUBLISH                0.051457\n",
       "CODE_GENDER_M                  0.054713\n",
       "DAYS_LAST_PHONE_CHANGE         0.055218\n",
       "NAME_INCOME_TYPE_Working       0.057481\n",
       "REGION_RATING_CLIENT           0.058899\n",
       "REGION_RATING_CLIENT_W_CITY    0.060893\n",
       "DAYS_EMPLOYED                  0.074958\n",
       "DAYS_BIRTH                     0.078239\n",
       "TARGET                         1.000000\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_train.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "### Pick columns with correlation >= 0.02 or correlation <= -0.02\n",
    "corr_cols = corr_train.index[(corr_train.values>=0.02)|(corr_train.values<=-0.02)].tolist()\n",
    "print(len(corr_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EXT_SOURCE_3',\n",
       " 'EXT_SOURCE_2',\n",
       " 'EXT_SOURCE_1',\n",
       " 'NAME_EDUCATION_TYPE_Higher education',\n",
       " 'CODE_GENDER_F',\n",
       " 'NAME_INCOME_TYPE_Pensioner',\n",
       " 'DAYS_EMPLOYED_ANOM',\n",
       " 'ORGANIZATION_TYPE_XNA',\n",
       " 'FLOORSMAX_AVG',\n",
       " 'FLOORSMAX_MEDI',\n",
       " 'FLOORSMAX_MODE',\n",
       " 'EMERGENCYSTATE_MODE_No',\n",
       " 'HOUSETYPE_MODE_block of flats',\n",
       " 'AMT_GOODS_PRICE',\n",
       " 'REGION_POPULATION_RELATIVE',\n",
       " 'ELEVATORS_AVG',\n",
       " 'ELEVATORS_MEDI',\n",
       " 'FLOORSMIN_AVG',\n",
       " 'FLOORSMIN_MEDI',\n",
       " 'WALLSMATERIAL_MODE_Panel',\n",
       " 'LIVINGAREA_AVG',\n",
       " 'LIVINGAREA_MEDI',\n",
       " 'FLOORSMIN_MODE',\n",
       " 'TOTALAREA_MODE',\n",
       " 'ELEVATORS_MODE',\n",
       " 'NAME_CONTRACT_TYPE_Revolving loans',\n",
       " 'LIVINGAREA_MODE',\n",
       " 'AMT_CREDIT',\n",
       " 'APARTMENTS_AVG',\n",
       " 'APARTMENTS_MEDI',\n",
       " 'FLAG_DOCUMENT_6',\n",
       " 'NAME_HOUSING_TYPE_House / apartment',\n",
       " 'APARTMENTS_MODE',\n",
       " 'NAME_FAMILY_STATUS_Married',\n",
       " 'LIVINGAPARTMENTS_AVG',\n",
       " 'LIVINGAPARTMENTS_MEDI',\n",
       " 'HOUR_APPR_PROCESS_START',\n",
       " 'FLAG_PHONE',\n",
       " 'NAME_INCOME_TYPE_State servant',\n",
       " 'LIVINGAPARTMENTS_MODE',\n",
       " 'BASEMENTAREA_AVG',\n",
       " 'FONDKAPREMONT_MODE_reg oper account',\n",
       " 'YEARS_BUILD_MEDI',\n",
       " 'YEARS_BUILD_AVG',\n",
       " 'BASEMENTAREA_MEDI',\n",
       " 'YEARS_BUILD_MODE',\n",
       " 'FLAG_OWN_CAR_Y',\n",
       " 'OCCUPATION_TYPE_Accountants',\n",
       " 'OCCUPATION_TYPE_Core staff',\n",
       " 'FLAG_OWN_CAR_N',\n",
       " 'NAME_FAMILY_STATUS_Civil marriage',\n",
       " 'ORGANIZATION_TYPE_Business Entity Type 3',\n",
       " 'NAME_FAMILY_STATUS_Single / not married',\n",
       " 'OCCUPATION_TYPE_Low-skill Laborers',\n",
       " 'FLAG_WORK_PHONE',\n",
       " 'ORGANIZATION_TYPE_Self-employed',\n",
       " 'NAME_HOUSING_TYPE_With parents',\n",
       " 'OCCUPATION_TYPE_Drivers',\n",
       " 'NAME_CONTRACT_TYPE_Cash loans',\n",
       " 'DEF_60_CNT_SOCIAL_CIRCLE',\n",
       " 'DEF_30_CNT_SOCIAL_CIRCLE',\n",
       " 'LIVE_CITY_NOT_WORK_CITY',\n",
       " 'OWN_CAR_AGE',\n",
       " 'DAYS_REGISTRATION',\n",
       " 'OCCUPATION_TYPE_Laborers',\n",
       " 'FLAG_DOCUMENT_3',\n",
       " 'REG_CITY_NOT_LIVE_CITY',\n",
       " 'FLAG_EMP_PHONE',\n",
       " 'NAME_EDUCATION_TYPE_Secondary / secondary special',\n",
       " 'REG_CITY_NOT_WORK_CITY',\n",
       " 'DAYS_ID_PUBLISH',\n",
       " 'CODE_GENDER_M',\n",
       " 'DAYS_LAST_PHONE_CHANGE',\n",
       " 'NAME_INCOME_TYPE_Working',\n",
       " 'REGION_RATING_CLIENT',\n",
       " 'REGION_RATING_CLIENT_W_CITY',\n",
       " 'DAYS_EMPLOYED',\n",
       " 'DAYS_BIRTH',\n",
       " 'TARGET']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 79) (48744, 78)\n"
     ]
    }
   ],
   "source": [
    "### Choose columns with high correlation in magnitude only for comparison purposes\n",
    "data_train = DF_train[corr_cols].copy()\n",
    "data_test = DF_test[corr_cols[:-1]].copy()\n",
    "print(data_train.shape,data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>NAME_EDUCATION_TYPE_Higher education</th>\n",
       "      <th>CODE_GENDER_F</th>\n",
       "      <th>NAME_INCOME_TYPE_Pensioner</th>\n",
       "      <th>DAYS_EMPLOYED_ANOM</th>\n",
       "      <th>ORGANIZATION_TYPE_XNA</th>\n",
       "      <th>FLOORSMAX_AVG</th>\n",
       "      <th>FLOORSMAX_MEDI</th>\n",
       "      <th>...</th>\n",
       "      <th>REG_CITY_NOT_WORK_CITY</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>CODE_GENDER_M</th>\n",
       "      <th>DAYS_LAST_PHONE_CHANGE</th>\n",
       "      <th>NAME_INCOME_TYPE_Working</th>\n",
       "      <th>REGION_RATING_CLIENT</th>\n",
       "      <th>REGION_RATING_CLIENT_W_CITY</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.139376</td>\n",
       "      <td>0.262949</td>\n",
       "      <td>0.083037</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-2120</td>\n",
       "      <td>1</td>\n",
       "      <td>-1134.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-637.0</td>\n",
       "      <td>-9461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.622246</td>\n",
       "      <td>0.311267</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-291</td>\n",
       "      <td>0</td>\n",
       "      <td>-828.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1188.0</td>\n",
       "      <td>-16765</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.729567</td>\n",
       "      <td>0.555912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-2531</td>\n",
       "      <td>1</td>\n",
       "      <td>-815.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-19046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EXT_SOURCE_3  EXT_SOURCE_2  EXT_SOURCE_1  \\\n",
       "0      0.139376      0.262949      0.083037   \n",
       "1           NaN      0.622246      0.311267   \n",
       "2      0.729567      0.555912           NaN   \n",
       "\n",
       "   NAME_EDUCATION_TYPE_Higher education  CODE_GENDER_F  \\\n",
       "0                                     0              0   \n",
       "1                                     1              1   \n",
       "2                                     0              0   \n",
       "\n",
       "   NAME_INCOME_TYPE_Pensioner  DAYS_EMPLOYED_ANOM  ORGANIZATION_TYPE_XNA  \\\n",
       "0                           0                   0                      0   \n",
       "1                           0                   0                      0   \n",
       "2                           0                   0                      0   \n",
       "\n",
       "   FLOORSMAX_AVG  FLOORSMAX_MEDI  ...  REG_CITY_NOT_WORK_CITY  \\\n",
       "0         0.0833          0.0833  ...                       0   \n",
       "1         0.2917          0.2917  ...                       0   \n",
       "2            NaN             NaN  ...                       0   \n",
       "\n",
       "   DAYS_ID_PUBLISH  CODE_GENDER_M  DAYS_LAST_PHONE_CHANGE  \\\n",
       "0            -2120              1                 -1134.0   \n",
       "1             -291              0                  -828.0   \n",
       "2            -2531              1                  -815.0   \n",
       "\n",
       "   NAME_INCOME_TYPE_Working  REGION_RATING_CLIENT  \\\n",
       "0                         1                     2   \n",
       "1                         0                     1   \n",
       "2                         1                     2   \n",
       "\n",
       "   REGION_RATING_CLIENT_W_CITY  DAYS_EMPLOYED  DAYS_BIRTH  TARGET  \n",
       "0                            2         -637.0       -9461       1  \n",
       "1                            1        -1188.0      -16765       0  \n",
       "2                            2         -225.0      -19046       0  \n",
       "\n",
       "[3 rows x 79 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>NAME_EDUCATION_TYPE_Higher education</th>\n",
       "      <th>CODE_GENDER_F</th>\n",
       "      <th>NAME_INCOME_TYPE_Pensioner</th>\n",
       "      <th>DAYS_EMPLOYED_ANOM</th>\n",
       "      <th>ORGANIZATION_TYPE_XNA</th>\n",
       "      <th>FLOORSMAX_AVG</th>\n",
       "      <th>FLOORSMAX_MEDI</th>\n",
       "      <th>...</th>\n",
       "      <th>NAME_EDUCATION_TYPE_Secondary / secondary special</th>\n",
       "      <th>REG_CITY_NOT_WORK_CITY</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>CODE_GENDER_M</th>\n",
       "      <th>DAYS_LAST_PHONE_CHANGE</th>\n",
       "      <th>NAME_INCOME_TYPE_Working</th>\n",
       "      <th>REGION_RATING_CLIENT</th>\n",
       "      <th>REGION_RATING_CLIENT_W_CITY</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.159520</td>\n",
       "      <td>0.789654</td>\n",
       "      <td>0.752614</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-812</td>\n",
       "      <td>0</td>\n",
       "      <td>-1740.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-2329.0</td>\n",
       "      <td>-19241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.432962</td>\n",
       "      <td>0.291656</td>\n",
       "      <td>0.564990</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1623</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-4469.0</td>\n",
       "      <td>-18064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.610991</td>\n",
       "      <td>0.699787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3503</td>\n",
       "      <td>1</td>\n",
       "      <td>-856.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-4458.0</td>\n",
       "      <td>-20038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EXT_SOURCE_3  EXT_SOURCE_2  EXT_SOURCE_1  \\\n",
       "0      0.159520      0.789654      0.752614   \n",
       "1      0.432962      0.291656      0.564990   \n",
       "2      0.610991      0.699787           NaN   \n",
       "\n",
       "   NAME_EDUCATION_TYPE_Higher education  CODE_GENDER_F  \\\n",
       "0                                     1              1   \n",
       "1                                     0              0   \n",
       "2                                     1              0   \n",
       "\n",
       "   NAME_INCOME_TYPE_Pensioner  DAYS_EMPLOYED_ANOM  ORGANIZATION_TYPE_XNA  \\\n",
       "0                           0                   0                      0   \n",
       "1                           0                   0                      0   \n",
       "2                           0                   0                      0   \n",
       "\n",
       "   FLOORSMAX_AVG  FLOORSMAX_MEDI  ...  \\\n",
       "0          0.125           0.125  ...   \n",
       "1            NaN             NaN  ...   \n",
       "2            NaN             NaN  ...   \n",
       "\n",
       "   NAME_EDUCATION_TYPE_Secondary / secondary special  REG_CITY_NOT_WORK_CITY  \\\n",
       "0                                                  0                       0   \n",
       "1                                                  1                       0   \n",
       "2                                                  0                       0   \n",
       "\n",
       "   DAYS_ID_PUBLISH  CODE_GENDER_M  DAYS_LAST_PHONE_CHANGE  \\\n",
       "0             -812              0                 -1740.0   \n",
       "1            -1623              1                     0.0   \n",
       "2            -3503              1                  -856.0   \n",
       "\n",
       "   NAME_INCOME_TYPE_Working  REGION_RATING_CLIENT  \\\n",
       "0                         1                     2   \n",
       "1                         1                     2   \n",
       "2                         1                     2   \n",
       "\n",
       "   REGION_RATING_CLIENT_W_CITY  DAYS_EMPLOYED  DAYS_BIRTH  \n",
       "0                            2        -2329.0      -19241  \n",
       "1                            2        -4469.0      -18064  \n",
       "2                            2        -4458.0      -20038  \n",
       "\n",
       "[3 rows x 78 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307511 (307511, 242) (48744, 242) (307511, 78) (48744, 78) 242 78\n"
     ]
    }
   ],
   "source": [
    "train_labels = DF_train['TARGET']\n",
    "train_ids = DF_train['SK_ID_CURR']\n",
    "test_ids = DF_test['SK_ID_CURR']\n",
    "df_train = DF_train.drop(labels=['SK_ID_CURR','TARGET'],axis=1)\n",
    "df_test = DF_test.drop(labels=['SK_ID_CURR'],axis=1)\n",
    "df_train,df_test = df_train.align(df_test,join='inner',axis=1)\n",
    "data_train,data_test = data_train.align(data_test,join='inner',axis=1)\n",
    "df_features = df_train.columns\n",
    "data_features = data_train.columns\n",
    "print(len(train_labels),df_train.shape,df_test.shape,data_train.shape,data_test.shape,len(df_features),len(data_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute missing values and scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Impute missing values with median values\n",
    "imputer = SimpleImputer(missing_values=np.nan,strategy='median')\n",
    "imputer.fit(df_train)\n",
    "df_train = imputer.transform(df_train)\n",
    "df_test = imputer.transform(df_test)\n",
    "imputer.fit(data_train)\n",
    "data_train = imputer.transform(data_train)\n",
    "data_test = imputer.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scale each feature to a value between 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit(df_train)\n",
    "df_train = scaler.transform(df_train)\n",
    "df_test = scaler.transform(df_test)\n",
    "scaler.fit(data_train)\n",
    "data_train = scaler.transform(data_train)\n",
    "data_test = scaler.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 242) (48744, 242) (307511, 78) (48744, 78)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape,df_test.shape,data_train.shape,data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split training data into 3 folds for validation\n",
    "kfold = KFold(n_splits=3,shuffle=False,random_state=None)\n",
    "### Create the model with the specified regularization parameter\n",
    "logit = LogisticRegression(C=0.001)   # Lower C signifies stronger regularization to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  [102504 102505 102506]  -  [307508 307509 307510] , Validation:  [0 1 2]  -  [102501 102502 102503]\n",
      "Score for the prediction =  0.918822680090533\n",
      "--------------------------------------------------\n",
      "Train:  [0 1 2]  -  [307508 307509 307510] , Validation:  [102504 102505 102506]  -  [205005 205006 205007]\n",
      "Score for the prediction =  0.918812924373683\n",
      "--------------------------------------------------\n",
      "Train:  [0 1 2]  -  [205005 205006 205007] , Validation:  [205008 205009 205010]  -  [307508 307509 307510]\n",
      "Score for the prediction =  0.9201779460113363\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "### Specify which training dataset to use\n",
    "df = df_train.copy()\n",
    "for index_train,index_valid in kfold.split(df):\n",
    "    print('Train: ',index_train[:3],' - ',index_train[-3:],', Validation: ',index_valid[:3],' - ',index_valid[-3:])\n",
    "    ### Define the training and validation sets\n",
    "    train_set,train_target = df[index_train],train_labels[index_train]\n",
    "    valid_set,valid_target = df[index_valid],train_labels[index_valid]\n",
    "    ### Train the model\n",
    "    logit.fit(train_set,train_target)\n",
    "    ### Find the mean accuracy of the prediction (mean score)\n",
    "    predict_score = logit.score(valid_set,valid_target)\n",
    "    print('Score for the prediction = ',predict_score)\n",
    "    print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  [102504 102505 102506]  -  [307508 307509 307510] , Validation:  [0 1 2]  -  [102501 102502 102503]\n",
      "Score for the prediction =  0.918822680090533\n",
      "Train:  [0 1 2]  -  [307508 307509 307510] , Validation:  [102504 102505 102506]  -  [205005 205006 205007]\n",
      "Score for the prediction =  0.918812924373683\n",
      "Train:  [0 1 2]  -  [205005 205006 205007] , Validation:  [205008 205009 205010]  -  [307508 307509 307510]\n",
      "Score for the prediction =  0.9201779460113363\n"
     ]
    }
   ],
   "source": [
    "### Specify which training dataset to use\n",
    "df = data_train.copy()\n",
    "for index_train,index_valid in kfold.split(df):\n",
    "    print('Train: ',index_train[:3],' - ',index_train[-3:],', Validation: ',index_valid[:3],' - ',index_valid[-3:])\n",
    "    ### Define the training and validation sets\n",
    "    train_set,train_target = df[index_train],train_labels[index_train]\n",
    "    valid_set,valid_target = df[index_valid],train_labels[index_valid]\n",
    "    ### Train the model\n",
    "    logit.fit(train_set,train_target)\n",
    "    ### Find the mean accuracy of the prediction (mean score)\n",
    "    predict_score = logit.score(valid_set,valid_target)\n",
    "    print('Score for the prediction = ',predict_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all features (246 features) are the same as using features with correlation of at least 0.02 in magnitude (78 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predict the TARGET probabilities for the testing data\n",
    "logit = LogisticRegression(C=0.001)\n",
    "logit.fit(df_train,train_labels)\n",
    "### First column is the probability of TARGET=0, second column is of TARGET=1\n",
    "prob_logit = logit.predict_proba(df_test)[:,1]\n",
    "### Create a dataframe of the prediction\n",
    "df_logit = pd.DataFrame(list(zip(test_ids,prob_logit)),columns=['SK_ID_CURR','prob_logit'])\n",
    "# df_logit.to_csv('Predicted_probability_logit.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>prob_logit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.057738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>0.181311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>0.041129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  prob_logit\n",
       "0      100001    0.057738\n",
       "1      100005    0.181311\n",
       "2      100013    0.041129"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_logit.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the training data into 3 folds for validation\n",
    "kfold = KFold(n_splits=3,shuffle=False,random_state=None)\n",
    "### Create the random forest classifier\n",
    "randomforest = RandomForestClassifier(n_estimators=100,n_jobs=-1,bootstrap=True,random_state=10,verbose=1,\n",
    "                                      warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  [102504 102505 102506]  -  [307508 307509 307510] , Validation:  [0 1 2]  -  [102501 102502 102503]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   32.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for the prediction =  0.9188909701084835\n",
      "--------------------------------------------------\n",
      "Train:  [0 1 2]  -  [307508 307509 307510] , Validation:  [102504 102505 102506]  -  [205005 205006 205007]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for the prediction =  0.9189007258253337\n",
      "--------------------------------------------------\n",
      "Train:  [0 1 2]  -  [205005 205006 205007] , Validation:  [205008 205009 205010]  -  [307508 307509 307510]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for the prediction =  0.9202267250714613\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    2.5s finished\n"
     ]
    }
   ],
   "source": [
    "### Specify which training dataset to use\n",
    "df = df_train.copy()\n",
    "for index_train,index_valid in kfold.split(df):\n",
    "    print('Train: ',index_train[:3],' - ',index_train[-3:],', Validation: ',index_valid[:3],' - ',index_valid[-3:])\n",
    "    ### Define the training and validation sets\n",
    "    train_set,train_target = df[index_train],train_labels[index_train]\n",
    "    valid_set,valid_target = df[index_valid],train_labels[index_valid]\n",
    "    ### Train the random forest classifier\n",
    "    randomforest.fit(train_set,train_target)\n",
    "    ### Find the accuracy of the prediction (mean score)\n",
    "    predict_score = randomforest.score(valid_set,valid_target)\n",
    "    print('Score for the prediction = ',predict_score)\n",
    "    print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  [102504 102505 102506]  -  [307508 307509 307510] , Validation:  [0 1 2]  -  [102501 102502 102503]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   41.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for the prediction =  0.9188519472410833\n",
      "--------------------------------------------------\n",
      "Train:  [0 1 2]  -  [307508 307509 307510] , Validation:  [102504 102505 102506]  -  [205005 205006 205007]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   42.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for the prediction =  0.9188909701084835\n",
      "--------------------------------------------------\n",
      "Train:  [0 1 2]  -  [205005 205006 205007] , Validation:  [205008 205009 205010]  -  [307508 307509 307510]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   43.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for the prediction =  0.9203828180638616\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "### Specify which training dataset to use\n",
    "df = data_train.copy()\n",
    "for index_train,index_valid in kfold.split(df):\n",
    "    print('Train: ',index_train[:3],' - ',index_train[-3:],', Validation: ',index_valid[:3],' - ',index_valid[-3:])\n",
    "    ### Define the training and validation sets\n",
    "    train_set,train_target = df[index_train],train_labels[index_train]\n",
    "    valid_set,valid_target = df[index_valid],train_labels[index_valid]\n",
    "    ### Train the random forest classifier\n",
    "    randomforest.fit(train_set,train_target)\n",
    "    ### Find the accuracy of the prediction (mean score)\n",
    "    predict_score = randomforest.score(valid_set,valid_target)\n",
    "    print('Score for the prediction = ',predict_score)\n",
    "    print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   56.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.3s finished\n"
     ]
    }
   ],
   "source": [
    "### Predict the TARGET probabilities for the testing data\n",
    "randomforest = RandomForestClassifier(n_estimators=100,n_jobs=-1,bootstrap=True,random_state=10,verbose=1,\n",
    "                                      warm_start=False)\n",
    "randomforest.fit(df_train,train_labels)\n",
    "### First column is the probability of TARGET=0, second column is of TARGET=1\n",
    "prob_randomforest = randomforest.predict_proba(df_test)[:,1]\n",
    "### Create a dataframe of the prediction\n",
    "df_randomforest = pd.DataFrame(list(zip(test_ids,prob_randomforest)),columns=['SK_ID_CURR','prob_randomforest'])\n",
    "# df_randomforest.to_csv('Predicted_probability_randomforest.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>prob_randomforest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  prob_randomforest\n",
       "0      100001               0.10\n",
       "1      100005               0.07\n",
       "2      100013               0.07"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_randomforest.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light Gradient Boosting Machine (LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the training data into 2 folds for validation\n",
    "kfold = KFold(n_splits=2,shuffle=False,random_state=None)\n",
    "### Create the lightgbm classifier\n",
    "lgbmc = lgb.LGBMClassifier(boosting_type='gbdt',n_estimators=10000,objective='binary',class_weight='balanced',\n",
    "                           learning_rate=0.05,reg_alpha=0.1,reg_lambda=0.1,subsample=0.8,n_jobs=-1,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  [153756 153757 153758]  -  [307508 307509 307510] , Validation:  [0 1 2]  -  [153753 153754 153755]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[209]\ttrain's auc: 0.815676\ttrain's binary_logloss: 0.532485\tvalid's auc: 0.754774\tvalid's binary_logloss: 0.556767\n",
      "Best iteration =  209\n",
      "Best validation score =  0.7547742806632167 , Binary logloss =  0.5567669110728659\n",
      "Best train score =  0.8156759369447579 , Binary logloss =  0.5324846702245478\n",
      "--------------------------------------------------\n",
      "Train:  [0 1 2]  -  [153753 153754 153755] , Validation:  [153756 153757 153758]  -  [307508 307509 307510]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[208]\ttrain's auc: 0.816302\ttrain's binary_logloss: 0.532194\tvalid's auc: 0.755306\tvalid's binary_logloss: 0.552866\n",
      "Best iteration =  208\n",
      "Best validation score =  0.75530593340672 , Binary logloss =  0.5528655256155516\n",
      "Best train score =  0.8163016548860262 , Binary logloss =  0.5321935644513691\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "### Specify which training and testing dataset to use\n",
    "df1 = df_train.copy()\n",
    "df2 = df_test.copy()\n",
    "prob_lgbm1 = np.zeros(len(df2))   # Empty array to store prediction\n",
    "for index_train,index_valid in kfold.split(df1):\n",
    "    print('Train: ',index_train[:3],' - ',index_train[-3:],', Validation: ',index_valid[:3],' - ',index_valid[-3:])\n",
    "    ### Define the training and testing sets\n",
    "    train_set,train_target = df1[index_train],train_labels[index_train]\n",
    "    valid_set,valid_target = df1[index_valid],train_labels[index_valid]\n",
    "    ### Train the LightGBM classifier\n",
    "    lgbmc.fit(train_set,train_target,eval_set=[(valid_set,valid_target),(train_set,train_target)],\n",
    "              eval_names=['valid','train'],eval_metric='auc',early_stopping_rounds=100,verbose=400)\n",
    "    ### Find the best iteration of the prediction\n",
    "    best_iter = lgbmc.best_iteration_\n",
    "    print('Best iteration = ',best_iter)\n",
    "    ### Find the best score of the prediction\n",
    "    valid_score_auc = lgbmc.best_score_['valid']['auc']\n",
    "    valid_score_loss = lgbmc.best_score_['valid']['binary_logloss']\n",
    "    train_score_auc = lgbmc.best_score_['train']['auc']\n",
    "    train_score_loss = lgbmc.best_score_['train']['binary_logloss']\n",
    "    print('Best validation score = ',valid_score_auc,', Binary logloss = ',valid_score_loss)\n",
    "    print('Best train score = ',train_score_auc,', Binary logloss = ',train_score_loss)\n",
    "    ### Predict the TARGET probabilities for testing data and take average\n",
    "    prob_lgbm1 += lgbmc.predict_proba(df2,num_iteration=best_iter)[:,1]/kfold.n_splits\n",
    "    print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  [153756 153757 153758]  -  [307508 307509 307510] , Validation:  [0 1 2]  -  [153753 153754 153755]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[163]\ttrain's auc: 0.799618\ttrain's binary_logloss: 0.547363\tvalid's auc: 0.752088\tvalid's binary_logloss: 0.56732\n",
      "Best iteration =  163\n",
      "Best validation score =  0.7520878377259169 , Binary logloss =  0.5673197718955182\n",
      "Best train score =  0.7996179659173639 , Binary logloss =  0.5473630947715845\n",
      "--------------------------------------------------\n",
      "Train:  [0 1 2]  -  [153753 153754 153755] , Validation:  [153756 153757 153758]  -  [307508 307509 307510]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[219]\ttrain's auc: 0.813198\ttrain's binary_logloss: 0.5347\tvalid's auc: 0.752222\tvalid's binary_logloss: 0.555311\n",
      "Best iteration =  219\n",
      "Best validation score =  0.752221666977963 , Binary logloss =  0.5553108774962282\n",
      "Best train score =  0.8131980126464283 , Binary logloss =  0.5346997075460918\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "### Specify which training and testing dataset to use\n",
    "df3 = data_train.copy()\n",
    "df4 = data_test.copy()\n",
    "prob_lgbm2 = np.zeros(len(df4))   # Empty array to store prediction\n",
    "for index_train,index_valid in kfold.split(df3):\n",
    "    print('Train: ',index_train[:3],' - ',index_train[-3:],', Validation: ',index_valid[:3],' - ',index_valid[-3:])\n",
    "    ### Define the training and testing sets\n",
    "    train_set,train_target = df3[index_train],train_labels[index_train]\n",
    "    valid_set,valid_target = df3[index_valid],train_labels[index_valid]\n",
    "    ### Train the LightGBM classifier\n",
    "    lgbmc.fit(train_set,train_target,eval_set=[(valid_set,valid_target),(train_set,train_target)],\n",
    "              eval_names=['valid','train'],eval_metric='auc',early_stopping_rounds=100,verbose=400)\n",
    "    ### Find the best iteration of the prediction\n",
    "    best_iter = lgbmc.best_iteration_\n",
    "    print('Best iteration = ',best_iter)\n",
    "    ### Find the best score of the prediction\n",
    "    valid_score_auc = lgbmc.best_score_['valid']['auc']\n",
    "    valid_score_loss = lgbmc.best_score_['valid']['binary_logloss']\n",
    "    train_score_auc = lgbmc.best_score_['train']['auc']\n",
    "    train_score_loss = lgbmc.best_score_['train']['binary_logloss']\n",
    "    print('Best validation score = ',valid_score_auc,', Binary logloss = ',valid_score_loss)\n",
    "    print('Best train score = ',train_score_auc,', Binary logloss = ',train_score_loss)\n",
    "    ### Predict the TARGET probabilities for testing data and take average\n",
    "    prob_lgbm2 += lgbmc.predict_proba(df4,num_iteration=best_iter)[:,1]/kfold.n_splits\n",
    "    print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_lgbm = prob_lgbm1\n",
    "### Create a dataframe of the prediction\n",
    "df_lgbm = pd.DataFrame(list(zip(test_ids,prob_lgbm)),columns=['SK_ID_CURR','prob_lightgbm'])\n",
    "# df_lgbm.to_csv('Predicted_probability_lightgbm.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>prob_lightgbm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.259603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>0.569574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>0.170356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  prob_lightgbm\n",
       "0      100001       0.259603\n",
       "1      100005       0.569574\n",
       "2      100013       0.170356"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lgbm.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
